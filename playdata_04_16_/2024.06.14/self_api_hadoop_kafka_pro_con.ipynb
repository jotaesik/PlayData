from confluent_kafka import Producer
from pyarrow import fs
import configparser, os, subprocess

from pyarrow import fs 
import pandas as pd


classpath = subprocess.Popen(["/home/hadoop/hadoop/bin/hdfs", "classpath", "--glob"],
                 stdout=subprocess.PIPE).communicate()[0]
os.environ['CLASSPATH'] = classpath.decode('utf-8')
os.environ['ARROW_LIBHDFS_DIR'] = "/home/hadoop/hadoop/lib/native"
hdfs = fs.HadoopFileSystem(host='ip', port=port, user='hadoop')

df = pd.read_csv("/home/hadoop/hadoop_data/civilian_force.csv")

with hdfs.open_output_stream("/mort/tmp2.csv") as fs:
    line = df.iloc[:100].to_csv()
    fs.write(line.encode())

import subprocess
com = ["curl", "url",]
rt = subprocess.run(com,   capture_output=True, text=True)
 # rt.stdout

from xml.etree import ElementTree
root = ElementTree.fromstring(rt.stdout)
total = []
items = root.iter(tag='item') 
# busiId   statId  chgerId  stat  statUpdDt lastTsdt  lastTedt  nowTsdt 
for element in items:
    temp = []
    for x in element:
        # print(x.tag, x.text, end=", ")
        temp.append(x.text)
    # break
    # print()
    total.append(temp)


df = pd.DataFrame(total, columns=['busiId', 'statId', 'chgerId','stat','statUpdDt','lastTsdt','lastTedt','nowTsdt'])

df.to_csv("20240614_data.csv", index = False)


from confluent_kafka import Producer #카프카접속할때
from pyarrow import fs #하둡접속할때
import configparser, os ,subprocess #standard때문에
from confluent_kafka import Producer
from pyarrow import fs
import configparser, os, subprocess

class Hdfs2Kafka(object):
    def __init__(self):
        classpath = subprocess.Popen(["/home/hadoop/hadoop/bin/hdfs", "classpath", "--glob"],
                         stdout=subprocess.PIPE).communicate()[0]
        os.environ['CLASSPATH'] = classpath.decode('utf-8')
        os.environ['ARROW_LIBHDFS_DIR'] = "/home/hadoop/hadoop/lib/native"
        self._hdfs = fs.HadoopFileSystem(host='ip', port=port, user='hadoop')

        kafka_brokers = "ip:port"
        kafka_resetType = 'earliest'

        conf = {'bootstrap.servers' : kafka_brokers, 'auto.offset.reset' : kafka_resetType}
        self._producer = Producer(conf)

    def getHdFileInfo(self, filename):
        f_Info = self._hdfs.get_file_info(filename)
        print(f'파일 종류 : {str(f_Info.type)}')
        print(f'파일 경로 : {str(f_Info.path)}')
        print(f'파일 크기 : {str(f_Info.size)}')
        print(f'파일 수정일자 : {str(f_Info.mtime)}')

    def readHdFile(self, filename):
        with self._hdfs.open_input_file(filename) as f:
            read_data = f.read().decode('utf-8').splitlines()
            #tmp = []
            #for line in read_data:
            #    tmp.append(line.split(","))
            #return tmp
            return [line.split(",") for line in read_data]

    def sendData2Kafka(self, topic, list_line):
        for data in list_line:
            str_tmp = ",".join(data).split(",")
            modified_data = ",".join(str_tmp[:2]) + "," + ",".join(str_tmp[4:])
            print(modified_data)
            self._producer.poll(0)
            self._producer.produce(topic, value=modified_data.encode('utf-8'), 
                                callback = kafka_producer_call)
            self._producer.flush()

def kafka_producer_call(err, msg):
    if err is not None:
        print (f"실패한 메시지 : error={err}, message={msg}")
    else:
        print(f"전달한 메시지: {msg.topic()} [{msg.partition()}] @ {msg.offset()}")
        print(f"massge.topic = {msg.topic()}")
        print(f"massge.timestamp = {msg.timestamp()}")
        print(f"massge.key = {msg.key()}")
        print(f"massge.value = {msg.value().decode('utf-8')}")
        print(f"massge.partition = {msg.partition()}")
        print(f"massge.offset = {msg.offset()}")

test01 = Hdfs2Kafka()
test01.getHdFileInfo("/mort/20240614_data.csv")
temp = test01.readHdFile("/mort/20240614_data.csv")
test01.sendData2Kafka("encore_mort", temp)

from confluent_kafka import Consumer

conf = {'bootstrap.servers': "ip:port", 
        'group.id' : 'test-group',
         'auto.offset.reset' : 'earliest'}
consumer = Consumer(conf)
consumer.subscribe(['encore_mort'])
while(True):
    msg = consumer.poll(timeout=0.1)
    if msg is None:
        continue
    if msg.error():
        print(msg.error())
    else:
        print(msg.value().decode('utf-8'))
consumer.close()
