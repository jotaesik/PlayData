{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5291609-c0d3-4d03-b103-d64e2388e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fce1d22-1ba1-4c4d-bda8-61c9d646a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = spark.sparkContext.textFile(\"file:///home/hadoop/test.txt\")\n",
    "rdd1_2 = rdd1.flatMap(lambda x: x.split(\" \"))\n",
    "rdd1_3 = rdd1_2.map(lambda x : (x, 1))\n",
    "rdd1_4 = rdd1_3.reduceByKey(lambda a, b : a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d360384-ca6a-44f5-a66f-b28c70fb900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rdd1_5 = rdd1_4.map(lambda x : (x[1], x[0])).sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aad9de76-5c93-4414-a51b-eeeebdd9da12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9, 'Project'), (9, 'Gutenberg’s'), (18, 'Alice’s'), (18, 'in'), (18, 'Lewis'), (18, 'Carroll'), (18, 'Adventures'), (18, 'Wonderland'), (18, 'by'), (27, 'is'), (27, 'use'), (27, 'of'), (27, 'anyone'), (27, 'anywhere'), (27, 'at'), (27, 'no'), (27, 'This'), (27, 'eBook'), (27, 'for'), (27, 'the'), (27, 'cost'), (27, 'and'), (27, 'with')]\n"
     ]
    }
   ],
   "source": [
    "print(rdd1_5.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f9034f9-748a-4daf-8f43-4a44a2d0e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|Seqno|               Quote|\n",
      "+-----+--------------------+\n",
      "|    1|Be the change tha...|\n",
      "|    2|Everyone thinks o...|\n",
      "|    3|The purpose of ou...|\n",
      "|    4|            Be cool.|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\"Seqno\",\"Quote\"]\n",
    "data = [(\"1\", \"Be the change that you wish to see in the world\"),\n",
    "    (\"2\", \"Everyone thinks of changing the world, but no one thinks of changing himself.\"),\n",
    "    (\"3\", \"The purpose of our lives is to be happy.\"),\n",
    "    (\"4\", \"Be cool.\")]\n",
    "df = spark.createDataFrame(data,columns)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae660834-7ddc-4a5a-a036-e231dd2e7183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------------------------------------------------+\n",
      "|Seqno|Quote                                                                        |\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "|1    |Be the change that you wish to see in the world                              |\n",
      "|2    |Everyone thinks of changing the world, but no one thinks of changing himself.|\n",
      "|3    |The purpose of our lives is to be happy.                                     |\n",
      "|4    |Be cool.                                                                     |\n",
      "+-----+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6975b72c-174d-4be1-893d-ee756d626af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
    "rdd = spark.sparkContext.parallelize(dept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c17b6c77-0d79-4326-8b8a-4e76123d3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rdd.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b68b9d73-833c-4d40-bc1d-9b4b3aa0be3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e04285dd-e90a-4f0f-89c0-5bdc8bbbc877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|       _1| _2|\n",
      "+---------+---+\n",
      "|  Finance| 10|\n",
      "|Marketing| 20|\n",
      "|    Sales| 30|\n",
      "|       IT| 40|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acb716bd-eadb-4c72-ae96-f0e685c74b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "df2 = rdd.toDF(deptColumns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55129c9a-669a-4f53-adf1-0ddcbefb12d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|  Finance|     10|\n",
      "|Marketing|     20|\n",
      "|    Sales|     30|\n",
      "|       IT|     40|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2992125-9cce-4bec-a7cd-f32643cc9fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|James    |Smith   |USA    |CA   |\n",
      "|Michael  |Rose    |USA    |NY   |\n",
      "|Robert   |Williams|USA    |CA   |\n",
      "|Maria    |Jones   |USA    |FL   |\n",
      "+---------+--------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
    "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
    "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
    "  ]\n",
    "\n",
    "# Column names\n",
    "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53c009e7-dd15-45f6-a83f-b8a6c6e5d664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|firstname|lastname|\n",
      "+---------+--------+\n",
      "|    James|   Smith|\n",
      "|  Michael|    Rose|\n",
      "|   Robert|Williams|\n",
      "+---------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"firstname\",\"lastname\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c174f1aa-d6c9-4981-872a-dae3f6d0edf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|firstname|lastname|\n",
      "+---------+--------+\n",
      "|    James|   Smith|\n",
      "|  Michael|    Rose|\n",
      "|   Robert|Williams|\n",
      "+---------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"firstname\"], df[\"lastname\"]).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "210dd4bd-509b-4b1f-9f67-bf3bc1321fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|firstname|lastname|\n",
      "+---------+--------+\n",
      "|    James|   Smith|\n",
      "|  Michael|    Rose|\n",
      "|   Robert|Williams|\n",
      "+---------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.firstname, df.lastname).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f344adc-e4d3-419f-8585-df233c6ad8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|    James|   Smith|    USA|   CA|\n",
      "|  Michael|    Rose|    USA|   NY|\n",
      "|   Robert|Williams|    USA|   CA|\n",
      "|    Maria|   Jones|    USA|   FL|\n",
      "+---------+--------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.columns[:4]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d582b017-08b6-4d68-9ec0-ccc9fe4362f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------+\n",
      "|                name|state|gender|\n",
      "+--------------------+-----+------+\n",
      "|{James, null, Smith}|   OH|     M|\n",
      "|      {Anna, Rose, }|   NY|     F|\n",
      "| {Julia, , Williams}|   OH|     F|\n",
      "+--------------------+-----+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "        ((\"James\",None,\"Smith\"),\"OH\",\"M\"),\n",
    "        ((\"Anna\",\"Rose\",\"\"),\"NY\",\"F\"),\n",
    "        ((\"Julia\",\"\",\"Williams\"),\"OH\",\"F\"),\n",
    "        ((\"Maria\",\"Anne\",\"Jones\"),\"NY\",\"M\"),\n",
    "        ((\"Jen\",\"Mary\",\"Brown\"),\"NY\",\"M\"),\n",
    "        ((\"Mike\",\"Mary\",\"Williams\"),\"OH\",\"M\")\n",
    "        ]\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, StringType        \n",
    "schema = StructType([\n",
    "    StructField('name', StructType([\n",
    "         StructField('firstname', StringType(), True),\n",
    "         StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "         ])),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    "     ])\n",
    "df2 = spark.createDataFrame(data = data, schema = schema)\n",
    "df2.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46145711-fc70-4dbb-8218-f1191e2a1c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|name                |\n",
      "+--------------------+\n",
      "|{James, null, Smith}|\n",
      "|{Anna, Rose, }      |\n",
      "|{Julia, , Williams} |\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"name\").show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b23aa377-fe5f-4496-9882-8668b9e24c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|firstname|lastname|\n",
      "+---------+--------+\n",
      "|James    |Smith   |\n",
      "|Anna     |        |\n",
      "|Julia    |Williams|\n",
      "+---------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"name.firstname\",\"name.lastname\").show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca9250e0-b893-42d1-a2c8-6540f01f7382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+------+\n",
      "|firstname|middlename|lastname|gender|\n",
      "+---------+----------+--------+------+\n",
      "|    James|      null|   Smith|     M|\n",
      "|     Anna|      Rose|        |     F|\n",
      "|    Julia|          |Williams|     F|\n",
      "+---------+----------+--------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"name.*\", \"gender\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13b924a4-98b5-4d7f-8f0d-050e18e932dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "|Raman        |Finance   |CA   |99000 |40 |24000|\n",
      "|Scott        |Finance   |NY   |83000 |36 |19000|\n",
      "|Jen          |Finance   |NY   |79000 |53 |15000|\n",
      "|Jeff         |Marketing |CA   |80000 |25 |18000|\n",
      "|Kumar        |Marketing |NY   |91000 |50 |21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)\n",
    "  ]\n",
    "\n",
    "# Create DataFrame\n",
    "schema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cb416a3-7024-4346-849d-8413e1c3caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum,avg,max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d3cbc6a-27b4-46d7-93c2-cf7937ee460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "071be36a-3c5d-4307-b1ec-a1fbb1632897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sum(iterable, /, start=0)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9f50e7d-de6d-4fc6-a26c-561e5a2ea7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp  = df.groupby(\"department\").\\\n",
    "    agg(sum('salary').alias('sum_salary'),\\\n",
    "        avg('salary'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9fe2d70-f268-4866-8f86-03bce7344db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[department#196], functions=[sum(salary#198L), avg(salary#198L)])\n",
      "   +- Exchange hashpartitioning(department#196, 200), ENSURE_REQUIREMENTS, [plan_id=167]\n",
      "      +- HashAggregate(keys=[department#196], functions=[partial_sum(salary#198L), partial_avg(salary#198L)])\n",
      "         +- Project [department#196, salary#198L]\n",
      "            +- Scan ExistingRDD[employee_name#195,department#196,state#197,salary#198L,age#199L,bonus#200L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4da15528-d86a-41e5-b890-67431695109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+\n",
      "|department|sum_salary|      avg(salary)|\n",
      "+----------+----------+-----------------+\n",
      "|     Sales|    257000|85666.66666666667|\n",
      "|   Finance|    351000|          87750.0|\n",
      "| Marketing|    171000|          85500.0|\n",
      "+----------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42a1eaaa-8538-4e43-98a3-c26f928ca641",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp  = df.groupby(\"department\").\\\n",
    "    agg(sum('salary').alias('sum_salary'),\\\n",
    "        avg('salary').alias(\"avg_salary\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "986c2dca-d323-4bd4-a1d8-f02773552dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[department#196], functions=[sum(salary#198L), avg(salary#198L)])\n",
      "   +- Exchange hashpartitioning(department#196, 200), ENSURE_REQUIREMENTS, [plan_id=226]\n",
      "      +- HashAggregate(keys=[department#196], functions=[partial_sum(salary#198L), partial_avg(salary#198L)])\n",
      "         +- Project [department#196, salary#198L]\n",
      "            +- Scan ExistingRDD[employee_name#195,department#196,state#197,salary#198L,age#199L,bonus#200L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60bcb4c8-b482-4d54-bb42-c7d02c8ed322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+\n",
      "|department|sum_salary|       avg_salary|\n",
      "+----------+----------+-----------------+\n",
      "|     Sales|    257000|85666.66666666667|\n",
      "|   Finance|    351000|          87750.0|\n",
      "| Marketing|    171000|          85500.0|\n",
      "+----------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp.show(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
